# NewsGap åˆ†æè´¨é‡è·Ÿè¸ªç³»ç»Ÿ - è®¾è®¡æ–¹æ¡ˆ

> è®¾è®¡æ—¶é—´ï¼š2026-02-05  
> çŠ¶æ€ï¼šè®¾è®¡é˜¶æ®µï¼Œå¾…å®ç°

## ğŸ“Š ç³»ç»Ÿæ¦‚è¿°

åˆ†æè´¨é‡è·Ÿè¸ªç³»ç»Ÿçš„æ ¸å¿ƒç›®æ ‡æ˜¯ï¼š
1. **é‡åŒ–è¯„ä¼°**ï¼šç”¨æ•°æ®è¡¡é‡AIåˆ†ææŠ¥å‘Šçš„è´¨é‡
2. **æŒç»­ä¼˜åŒ–**ï¼šé€šè¿‡A/Bæµ‹è¯•å’Œåé¦ˆå¾ªç¯æ”¹è¿›Prompt
3. **æ€§èƒ½ç›‘æ§**ï¼šè¿½è¸ªLLMæ€§èƒ½ã€æˆæœ¬å’Œç”¨æˆ·æ»¡æ„åº¦

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    è´¨é‡è·Ÿè¸ªç³»ç»Ÿæ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   è´¨é‡è¯„åˆ†    â”‚    â”‚   A/Bæµ‹è¯•     â”‚    â”‚  æ€§èƒ½åˆ†æ    â”‚  â”‚
â”‚  â”‚   æ¨¡å—        â”‚    â”‚   æ¡†æ¶        â”‚    â”‚  ä»ªè¡¨æ¿      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                    â”‚                    â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                             â”‚                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚   æ•°æ®å­˜å‚¨å±‚     â”‚                       â”‚
â”‚                    â”‚  (quality_metrics)â”‚                     â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ æ•°æ®åº“è®¾è®¡

### 1. è´¨é‡è¯„åˆ†è¡¨ `quality_metrics`

```sql
CREATE TABLE quality_metrics (
    id TEXT PRIMARY KEY,
    analysis_id TEXT NOT NULL,
    
    -- è‡ªåŠ¨è¯„åˆ†æŒ‡æ ‡
    completeness_score REAL,          -- å®Œæ•´æ€§è¯„åˆ† (0-100)
    structure_score REAL,             -- ç»“æ„æ€§è¯„åˆ† (0-100)
    insight_density REAL,             -- æ´å¯Ÿå¯†åº¦ (insights/1000 words)
    readability_score REAL,           -- å¯è¯»æ€§è¯„åˆ† (Flesch)
    keyword_coverage REAL,            -- å…³é”®è¯è¦†ç›–ç‡ (0-100)
    overall_quality_score REAL,       -- ç»¼åˆè´¨é‡åˆ† (0-100)
    
    -- ç”¨æˆ·åé¦ˆ
    user_rating INTEGER,              -- ç”¨æˆ·è¯„åˆ† (1-5æ˜Ÿ)
    user_feedback TEXT,               -- ç”¨æˆ·æ–‡å­—åé¦ˆ
    user_helpful_vote BOOLEAN,        -- æ˜¯å¦æœ‰å¸®åŠ©
    
    -- æŠ€æœ¯æŒ‡æ ‡
    llm_backend TEXT,                 -- ä½¿ç”¨çš„LLM
    llm_model TEXT,                   -- å…·ä½“æ¨¡å‹
    prompt_version TEXT,              -- Promptç‰ˆæœ¬
    processing_time REAL,             -- å¤„ç†æ—¶é—´
    token_usage INTEGER,              -- Tokenä½¿ç”¨é‡
    estimated_cost REAL,              -- æˆæœ¬
    
    -- A/Bæµ‹è¯•
    experiment_id TEXT,               -- å®éªŒID
    variant TEXT,                     -- å˜ä½“ (A/B/C)
    
    -- å…ƒæ•°æ®
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (analysis_id) REFERENCES analyses(id)
);

CREATE INDEX idx_quality_experiment ON quality_metrics(experiment_id);
CREATE INDEX idx_quality_rating ON quality_metrics(user_rating);
CREATE INDEX idx_quality_model ON quality_metrics(llm_backend, llm_model);
CREATE INDEX idx_quality_score ON quality_metrics(overall_quality_score);
```

### 2. Promptç‰ˆæœ¬è¡¨ `prompt_versions`

```sql
CREATE TABLE prompt_versions (
    id TEXT PRIMARY KEY,
    industry TEXT NOT NULL,           -- è¡Œä¸šåˆ†ç±»
    analysis_type TEXT NOT NULL,      -- åˆ†æç±»å‹
    version TEXT NOT NULL,            -- ç‰ˆæœ¬å· (v1.0, v1.1)
    prompt_template TEXT NOT NULL,    -- Promptæ¨¡æ¿å†…å®¹
    
    -- æ€§èƒ½ç»Ÿè®¡
    usage_count INTEGER DEFAULT 0,    -- ä½¿ç”¨æ¬¡æ•°
    avg_quality_score REAL,           -- å¹³å‡è´¨é‡åˆ†
    avg_user_rating REAL,             -- å¹³å‡ç”¨æˆ·è¯„åˆ†
    
    -- ç‰ˆæœ¬æ§åˆ¶
    is_active BOOLEAN DEFAULT FALSE,  -- æ˜¯å¦ä¸ºå½“å‰ç‰ˆæœ¬
    parent_version TEXT,              -- çˆ¶ç‰ˆæœ¬ID
    change_description TEXT,          -- å˜æ›´è¯´æ˜
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by TEXT,                  -- åˆ›å»ºè€…
    
    UNIQUE(industry, analysis_type, version)
);

CREATE INDEX idx_prompt_active ON prompt_versions(industry, analysis_type, is_active);
```

### 3. A/Bæµ‹è¯•å®éªŒè¡¨ `experiments`

```sql
CREATE TABLE experiments (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    
    -- å®éªŒé…ç½®
    industry TEXT NOT NULL,
    analysis_type TEXT NOT NULL,
    variant_a_prompt_id TEXT,         -- å˜ä½“Açš„Prompt ID
    variant_b_prompt_id TEXT,         -- å˜ä½“Bçš„Prompt ID
    traffic_split REAL DEFAULT 0.5,   -- æµé‡åˆ†é…æ¯”ä¾‹ (0.0-1.0)
    
    -- å®éªŒçŠ¶æ€
    status TEXT DEFAULT 'draft',      -- draft/running/completed/cancelled
    start_date TIMESTAMP,
    end_date TIMESTAMP,
    
    -- ç»Ÿè®¡æ•°æ®
    variant_a_count INTEGER DEFAULT 0,
    variant_b_count INTEGER DEFAULT 0,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (variant_a_prompt_id) REFERENCES prompt_versions(id),
    FOREIGN KEY (variant_b_prompt_id) REFERENCES prompt_versions(id)
);

CREATE INDEX idx_experiment_status ON experiments(status);
CREATE INDEX idx_experiment_industry ON experiments(industry, analysis_type);
```

---

## ğŸ¯ è´¨é‡è¯„åˆ†ç®—æ³•

### 1. è‡ªåŠ¨è¯„åˆ†ç»´åº¦

#### A. å®Œæ•´æ€§è¯„åˆ† (Completeness Score)

æ£€æŸ¥æŠ¥å‘Šæ˜¯å¦åŒ…å«å¿…éœ€çš„ç« èŠ‚ï¼š

```python
def calculate_completeness_score(markdown_report: str, analysis_type: str) -> float:
    """
    è®¡ç®—æŠ¥å‘Šå®Œæ•´æ€§
    
    æ£€æŸ¥å¿…éœ€ç« èŠ‚æ˜¯å¦å­˜åœ¨
    
    Args:
        markdown_report: Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
        analysis_type: åˆ†æç±»å‹ (comprehensive, trend, signal, gap, brief)
        
    Returns:
        å®Œæ•´æ€§è¯„åˆ† (0-100)
    """
    required_sections = {
        'comprehensive': [
            '## ä¸€ã€æ ¸å¿ƒæ´å¯Ÿ',
            '## äºŒã€è¶‹åŠ¿åˆ†æ',
            '## ä¸‰ã€æ‰§è¡Œå»ºè®®',
            '## å››ã€é£é™©æç¤º'
        ],
        'trend': [
            '## è¶‹åŠ¿æ¦‚è¿°',
            '## å…³é”®æŒ‡æ ‡',
            '## è¶‹åŠ¿é¢„æµ‹'
        ],
        'signal': [
            '## ä¿¡å·èšç±»',
            '## å…³é”®äº‹ä»¶',
            '## ä¿¡å·å¼ºåº¦'
        ],
        'gap': [
            '## ä¿¡æ¯å·®è¯†åˆ«',
            '## æœºä¼šåˆ†æ'
        ],
        'brief': [
            '## æ‰§è¡Œæ‘˜è¦'
        ]
    }
    
    sections = required_sections.get(analysis_type, [])
    if not sections:
        return 100  # æœªçŸ¥ç±»å‹ï¼Œé»˜è®¤æ»¡åˆ†
    
    found_sections = sum(1 for section in sections if section in markdown_report)
    
    return (found_sections / len(sections)) * 100
```

#### B. ç»“æ„æ€§è¯„åˆ† (Structure Score)

è¯„ä¼°Markdownç»“æ„çš„è§„èŒƒæ€§ï¼š

```python
def calculate_structure_score(markdown_report: str) -> float:
    """
    è¯„ä¼°æŠ¥å‘Šç»“æ„è´¨é‡
    
    æ£€æŸ¥ï¼š
    - æ ‡é¢˜å±‚çº§æ˜¯å¦åˆç† (H1/H2/H3)
    - æ˜¯å¦æœ‰åˆ—è¡¨é¡¹
    - æ®µè½é•¿åº¦æ˜¯å¦é€‚ä¸­
    - æ˜¯å¦æœ‰ä»£ç å—æˆ–å¼•ç”¨
    
    Returns:
        ç»“æ„æ€§è¯„åˆ† (0-100)
    """
    lines = markdown_report.split('\n')
    
    # ç»Ÿè®¡å„çº§æ ‡é¢˜
    h1_count = sum(1 for line in lines if line.startswith('# '))
    h2_count = sum(1 for line in lines if line.startswith('## '))
    h3_count = sum(1 for line in lines if line.startswith('### '))
    
    # ç»Ÿè®¡åˆ—è¡¨
    list_count = sum(1 for line in lines if line.strip().startswith(('-', '*', '1.')))
    
    # ç»Ÿè®¡å¼•ç”¨
    quote_count = sum(1 for line in lines if line.strip().startswith('>'))
    
    # æ®µè½ç»Ÿè®¡
    paragraphs = [p for p in markdown_report.split('\n\n') if p.strip() and not p.startswith('#')]
    avg_paragraph_length = sum(len(p.split()) for p in paragraphs) / len(paragraphs) if paragraphs else 0
    
    # è¯„åˆ†é€»è¾‘
    score = 0
    
    # 1. æ ‡é¢˜ç»“æ„åˆç† (40åˆ†)
    # H1ä¸è¶…è¿‡1ä¸ªï¼Œæœ‰è¶³å¤Ÿçš„H2å’ŒH3
    if h1_count <= 1 and h2_count >= 3 and h3_count >= 2:
        score += 40
    elif h2_count >= 2:
        score += 20
    
    # 2. æœ‰åˆ—è¡¨é¡¹ (30åˆ†)
    if list_count >= 10:
        score += 30
    elif list_count >= 5:
        score += 20
    elif list_count >= 2:
        score += 10
    
    # 3. æ®µè½é•¿åº¦é€‚ä¸­ (20åˆ†)
    # ç†æƒ³èŒƒå›´ï¼š50-150è¯
    if 50 <= avg_paragraph_length <= 150:
        score += 20
    elif 30 <= avg_paragraph_length <= 200:
        score += 10
    
    # 4. æœ‰å¼•ç”¨æˆ–å¼ºè°ƒ (10åˆ†)
    if quote_count >= 2:
        score += 10
    elif quote_count >= 1:
        score += 5
    
    return min(score, 100)
```

#### C. æ´å¯Ÿå¯†åº¦ (Insight Density)

è¡¡é‡æŠ¥å‘Šä¸­å®è´¨æ€§æ´å¯Ÿçš„å¯†åº¦ï¼š

```python
def calculate_insight_density(markdown_report: str) -> float:
    """
    è®¡ç®—æ´å¯Ÿå¯†åº¦ï¼šæ¯1000è¯ä¸­çš„æ´å¯Ÿæ•°é‡
    
    æ´å¯Ÿè¯†åˆ«ç‰¹å¾ï¼š
    - åŒ…å«å…³é”®åŠ¨è¯ï¼šè¡¨æ˜ã€æ˜¾ç¤ºã€æ­ç¤ºã€å‘ç°ã€è¶‹åŠ¿ã€ä¿¡å·
    - ä½¿ç”¨æ•°æ®/æ•°å­—æ”¯æ’‘
    - æä¾›å»ºè®®æˆ–åˆ¤æ–­
    - å› æœå…³ç³»è¡¨è¿°
    
    Returns:
        æ´å¯Ÿå¯†åº¦ (æ¯1000è¯çš„æ´å¯Ÿæ•°)
    """
    import re
    
    # æ´å¯Ÿå…³é”®è¯æ¨¡å¼
    insight_patterns = [
        r'(è¡¨æ˜|æ˜¾ç¤º|æ­ç¤º|å‘ç°|è¶‹åŠ¿|ä¿¡å·|å»ºè®®|åº”å½“|éœ€è¦|å¯èƒ½|é¢„è®¡)',
        r'\d+%',                           # ç™¾åˆ†æ¯”
        r'\d+å€',                          # å€æ•°
        r'(ä¸Šå‡|ä¸‹é™|å¢é•¿|å‡å°‘|æå‡)\s*\d+', # å˜åŒ–æ•°æ®
        r'(å› ä¸º|ç”±äº|å¯¼è‡´|å¼•å‘|ä¿ƒä½¿)',       # å› æœå…³ç³»
        r'(ä½†æ˜¯|ç„¶è€Œ|ä¸è¿‡|å°½ç®¡)',           # è½¬æŠ˜å¯¹æ¯”
        r'(ç¬¬ä¸€|é¦–å…ˆ|å…¶æ¬¡|æœ€å|æ€»ä¹‹)',       # ç»“æ„åŒ–è¡¨è¿°
    ]
    
    insight_count = 0
    for pattern in insight_patterns:
        matches = re.findall(pattern, markdown_report)
        insight_count += len(matches)
    
    # è®¡ç®—è¯æ•° (ä¸­æ–‡æŒ‰å­—ç¬¦æ•°ï¼Œè‹±æ–‡æŒ‰å•è¯æ•°)
    # ç®€åŒ–ï¼šæŒ‰å­—ç¬¦æ•°è®¡ç®—
    char_count = len(re.sub(r'\s+', '', markdown_report))
    word_count = char_count  # ä¸­æ–‡1å­—=1è¯
    
    # æ¯1000è¯çš„æ´å¯Ÿæ•°
    density = (insight_count / word_count) * 1000 if word_count > 0 else 0
    
    return density
```

#### D. å¯è¯»æ€§è¯„åˆ† (Readability Score)

ä½¿ç”¨ç®€åŒ–çš„ä¸­æ–‡å¯è¯»æ€§è¯„åˆ†ï¼š

```python
def calculate_readability_score(markdown_report: str) -> float:
    """
    ç®€åŒ–çš„ä¸­æ–‡å¯è¯»æ€§è¯„åˆ†
    
    åŸºäºï¼š
    - å¹³å‡å¥å­é•¿åº¦
    - æ ‡ç‚¹ç¬¦å·ä½¿ç”¨é¢‘ç‡
    - æ®µè½ç»“æ„
    
    Returns:
        å¯è¯»æ€§è¯„åˆ† (0-100)ï¼Œåˆ†æ•°è¶Šé«˜è¶Šæ˜“è¯»
    """
    import re
    
    # ç§»é™¤Markdownæ ‡è®°
    text = re.sub(r'[#*`\[\]\(\)]', '', markdown_report)
    
    # ç»Ÿè®¡å¥å­
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
    sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 5]
    
    if not sentences:
        return 50
    
    # 1. å¹³å‡å¥å­é•¿åº¦ (å­—ç¬¦æ•°)
    avg_sentence_length = sum(len(s) for s in sentences) / len(sentences)
    
    # ç†æƒ³å¥é•¿ï¼š20-40å­—
    if 20 <= avg_sentence_length <= 40:
        length_score = 100
    elif avg_sentence_length < 20:
        length_score = 70 + (avg_sentence_length / 20) * 30
    elif avg_sentence_length <= 60:
        length_score = 100 - (avg_sentence_length - 40) * 1.5
    else:
        length_score = max(0, 100 - (avg_sentence_length - 40) * 2)
    
    # 2. æ ‡ç‚¹ç¬¦å·ä½¿ç”¨ (é€—å·ã€åˆ†å·å¸®åŠ©æ–­å¥)
    punctuation_count = len(re.findall(r'[ï¼Œ,ï¼›;ã€]', text))
    punctuation_ratio = punctuation_count / len(sentences) if sentences else 0
    
    # ç†æƒ³ï¼šæ¯å¥1-3ä¸ªæ–­å¥æ ‡ç‚¹
    if 1 <= punctuation_ratio <= 3:
        punctuation_score = 100
    else:
        punctuation_score = max(0, 100 - abs(punctuation_ratio - 2) * 20)
    
    # ç»¼åˆè¯„åˆ† (å¥é•¿æƒé‡70%ï¼Œæ ‡ç‚¹æƒé‡30%)
    score = length_score * 0.7 + punctuation_score * 0.3
    
    return round(score, 2)
```

#### E. å…³é”®è¯è¦†ç›–ç‡ (Keyword Coverage)

æ£€æŸ¥æŠ¥å‘Šæ˜¯å¦è¦†ç›–äº†æ–‡ç« ä¸­çš„å…³é”®ä¸»é¢˜ï¼š

```python
def calculate_keyword_coverage(markdown_report: str, articles: List[Article]) -> float:
    """
    è®¡ç®—æŠ¥å‘Šå¯¹æ–‡ç« å…³é”®è¯çš„è¦†ç›–ç‡
    
    æå–æ–‡ç« æ ‡é¢˜ä¸­çš„å…³é”®è¯ï¼Œæ£€æŸ¥æŠ¥å‘Šä¸­çš„è¦†ç›–æƒ…å†µ
    
    Args:
        markdown_report: æŠ¥å‘Šå†…å®¹
        articles: æºæ–‡ç« åˆ—è¡¨
        
    Returns:
        å…³é”®è¯è¦†ç›–ç‡ (0-100)
    """
    import jieba
    from collections import Counter
    
    # æå–æ–‡ç« å…³é”®è¯ (æ¥è‡ªæ ‡é¢˜)
    article_keywords = []
    for article in articles:
        # åˆ†è¯
        words = jieba.cut(article.title)
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        article_keywords.extend([w for w in words if len(w) > 1])
    
    # ç»Ÿè®¡é«˜é¢‘å…³é”®è¯
    keyword_freq = Counter(article_keywords)
    top_keywords = [k for k, v in keyword_freq.most_common(20)]
    
    if not top_keywords:
        return 100  # æ²¡æœ‰å…³é”®è¯ï¼Œé»˜è®¤æ»¡åˆ†
    
    # æ£€æŸ¥æŠ¥å‘Šè¦†ç›–æƒ…å†µ
    covered_keywords = sum(1 for kw in top_keywords if kw in markdown_report)
    
    coverage = (covered_keywords / len(top_keywords)) * 100
    
    return coverage
```

### 2. ç»¼åˆè´¨é‡åˆ†è®¡ç®—

```python
def calculate_overall_quality_score(metrics: dict) -> float:
    """
    è®¡ç®—ç»¼åˆè´¨é‡åˆ†
    
    åŠ æƒå¹³å‡ï¼š
    - å®Œæ•´æ€§: 25%
    - ç»“æ„æ€§: 20%
    - æ´å¯Ÿå¯†åº¦: 25%
    - å¯è¯»æ€§: 15%
    - å…³é”®è¯è¦†ç›–: 15%
    
    Args:
        metrics: åŒ…å«å„é¡¹æŒ‡æ ‡çš„å­—å…¸
        
    Returns:
        ç»¼åˆè´¨é‡åˆ† (0-100)
    """
    weights = {
        'completeness': 0.25,
        'structure': 0.20,
        'insight_density_normalized': 0.25,
        'readability': 0.15,
        'keyword_coverage': 0.15
    }
    
    # å½’ä¸€åŒ–æ´å¯Ÿå¯†åº¦åˆ°0-100èŒƒå›´
    # å‡è®¾ç†æƒ³å€¼ä¸º 5-15 insights/1000 words
    density = metrics.get('insight_density', 0)
    if density <= 5:
        normalized_density = (density / 5) * 70  # 5ä»¥ä¸‹çº¿æ€§æ˜ å°„åˆ°0-70
    elif density <= 15:
        normalized_density = 70 + (density - 5) / 10 * 30  # 5-15æ˜ å°„åˆ°70-100
    else:
        normalized_density = 100  # 15ä»¥ä¸Šéƒ½æ˜¯100
    
    metrics['insight_density_normalized'] = normalized_density
    
    # åŠ æƒæ±‚å’Œ
    overall_score = sum(
        metrics.get(metric, 0) * weight
        for metric, weight in weights.items()
    )
    
    return round(overall_score, 2)
```

---

## ğŸ”¬ A/Bæµ‹è¯•æ¡†æ¶

### å·¥ä½œæµç¨‹

```
1. åˆ›å»ºå®éªŒ
   â”œâ”€ å®šä¹‰å®éªŒåç§°å’Œç›®æ ‡
   â”œâ”€ é€‰æ‹©è¦æµ‹è¯•çš„ä¸¤ä¸ªPromptç‰ˆæœ¬
   â”œâ”€ è®¾ç½®æµé‡åˆ†é…æ¯”ä¾‹ (é»˜è®¤50/50)
   â””â”€ è®¾ç½®å®éªŒæ—¶é•¿å’Œæœ€å°æ ·æœ¬é‡

2. è¿è¡Œå®éªŒ
   â”œâ”€ ç”¨æˆ·è§¦å‘åˆ†æè¯·æ±‚
   â”œâ”€ ç³»ç»Ÿéšæœºåˆ†é…å˜ä½“ (Aæˆ–B)
   â”œâ”€ ä½¿ç”¨å¯¹åº”Promptç”Ÿæˆåˆ†æ
   â”œâ”€ è®°å½•å®éªŒæ•°æ® (å˜ä½“ã€è´¨é‡åˆ†ã€ç”¨æˆ·åé¦ˆ)
   â””â”€ æ›´æ–°å®éªŒç»Ÿè®¡

3. æ”¶é›†æ•°æ®
   â”œâ”€ è‡ªåŠ¨è´¨é‡è¯„åˆ† (5ä¸ªç»´åº¦)
   â”œâ”€ ç”¨æˆ·åé¦ˆè¯„åˆ† (å¯é€‰)
   â”œâ”€ æ€§èƒ½æŒ‡æ ‡ (æ—¶é—´ã€æˆæœ¬ã€Token)
   â””â”€ è¾¾åˆ°æœ€å°æ ·æœ¬é‡åå¯åˆ†æ

4. åˆ†æç»“æœ
   â”œâ”€ è®¡ç®—å„å˜ä½“çš„å¹³å‡è´¨é‡åˆ†
   â”œâ”€ ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ (t-test)
   â”œâ”€ è®¡ç®—æå‡å¹…åº¦ (lift)
   â””â”€ ç”Ÿæˆå®éªŒæŠ¥å‘Š

5. å†³ç­–
   â”œâ”€ ç¡®å®šè·èƒœå˜ä½“
   â”œâ”€ åœæ­¢å®éªŒ
   â”œâ”€ æ›´æ–°ç”Ÿäº§Prompt
   â””â”€ å½’æ¡£å®éªŒç»“æœ
```

### å®ç°ç¤ºä¾‹

```python
class ABTestManager:
    """A/Bæµ‹è¯•ç®¡ç†å™¨"""
    
    def __init__(self, db: Database):
        self.db = db
    
    async def assign_variant(
        self, 
        user_id: str, 
        experiment_id: str
    ) -> str:
        """
        ä¸ºç”¨æˆ·åˆ†é…å®éªŒå˜ä½“
        
        ä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œç¡®ä¿åŒä¸€ç”¨æˆ·æ€»æ˜¯çœ‹åˆ°ç›¸åŒå˜ä½“
        
        Args:
            user_id: ç”¨æˆ·ID (å¯ä»¥æ˜¯session ID)
            experiment_id: å®éªŒID
            
        Returns:
            'A' æˆ– 'B' æˆ– 'control'
        """
        import hashlib
        
        # è·å–å®éªŒé…ç½®
        experiment = await self.db.get_experiment(experiment_id)
        
        if not experiment or experiment.status != 'running':
            return 'control'  # å®éªŒæœªè¿è¡Œï¼Œä½¿ç”¨é»˜è®¤Prompt
        
        # ä¸€è‡´æ€§å“ˆå¸Œåˆ†é…
        hash_input = f"{user_id}:{experiment_id}"
        hash_value = int(hashlib.md5(hash_input.encode()).hexdigest(), 16)
        
        # æ ¹æ®traffic_splitå†³å®šåˆ†é…
        threshold = experiment.traffic_split
        normalized_hash = (hash_value % 100) / 100
        
        variant = 'A' if normalized_hash < threshold else 'B'
        
        return variant
    
    async def get_prompt_for_variant(
        self,
        experiment_id: str,
        variant: str
    ) -> str:
        """
        è·å–å®éªŒå˜ä½“å¯¹åº”çš„Prompt
        
        Args:
            experiment_id: å®éªŒID
            variant: 'A' æˆ– 'B'
            
        Returns:
            Promptæ¨¡æ¿å†…å®¹
        """
        experiment = await self.db.get_experiment(experiment_id)
        
        if variant == 'A':
            prompt_version = await self.db.get_prompt_version(experiment.variant_a_prompt_id)
        else:
            prompt_version = await self.db.get_prompt_version(experiment.variant_b_prompt_id)
        
        return prompt_version.prompt_template if prompt_version else None
    
    async def record_result(
        self,
        experiment_id: str,
        variant: str,
        analysis_id: str,
        quality_metrics: dict
    ):
        """
        è®°å½•å®éªŒç»“æœ
        
        Args:
            experiment_id: å®éªŒID
            variant: 'A' æˆ– 'B'
            analysis_id: åˆ†æID
            quality_metrics: è´¨é‡æŒ‡æ ‡å­—å…¸
        """
        # ä¿å­˜åˆ°quality_metricsè¡¨
        await self.db.save_quality_metrics({
            'analysis_id': analysis_id,
            'experiment_id': experiment_id,
            'variant': variant,
            **quality_metrics
        })
        
        # æ›´æ–°å®éªŒè®¡æ•°
        experiment = await self.db.get_experiment(experiment_id)
        if variant == 'A':
            experiment.variant_a_count += 1
        else:
            experiment.variant_b_count += 1
        
        await self.db.update_experiment(experiment)
    
    async def analyze_experiment(
        self,
        experiment_id: str
    ) -> dict:
        """
        åˆ†æå®éªŒç»“æœ
        
        è¿”å›ç»Ÿè®¡æ‘˜è¦å’Œæ˜¾è‘—æ€§æ£€éªŒç»“æœ
        
        Args:
            experiment_id: å®éªŒID
            
        Returns:
            å®éªŒåˆ†æç»“æœå­—å…¸
        """
        # è·å–å®éªŒæ•°æ®
        results = await self.db.get_quality_metrics_by_experiment(experiment_id)
        
        variant_a = [r for r in results if r['variant'] == 'A']
        variant_b = [r for r in results if r['variant'] == 'B']
        
        if len(variant_a) < 10 or len(variant_b) < 10:
            return {
                'error': 'æ ·æœ¬é‡ä¸è¶³',
                'min_samples': 10,
                'variant_a_samples': len(variant_a),
                'variant_b_samples': len(variant_b)
            }
        
        # è®¡ç®—å¹³å‡è´¨é‡åˆ†
        avg_quality_a = sum(r['overall_quality_score'] for r in variant_a) / len(variant_a)
        avg_quality_b = sum(r['overall_quality_score'] for r in variant_b) / len(variant_b)
        
        # è®¡ç®—å¹³å‡ç”¨æˆ·è¯„åˆ† (å¦‚æœæœ‰)
        rated_a = [r for r in variant_a if r.get('user_rating')]
        rated_b = [r for r in variant_b if r.get('user_rating')]
        
        avg_rating_a = sum(r['user_rating'] for r in rated_a) / len(rated_a) if rated_a else None
        avg_rating_b = sum(r['user_rating'] for r in rated_b) / len(rated_b) if rated_b else None
        
        # è®¡ç®—å¹³å‡æˆæœ¬
        avg_cost_a = sum(r['estimated_cost'] for r in variant_a) / len(variant_a)
        avg_cost_b = sum(r['estimated_cost'] for r in variant_b) / len(variant_b)
        
        # Tæ£€éªŒ (æ˜¾è‘—æ€§æ£€éªŒ)
        from scipy import stats
        quality_a = [r['overall_quality_score'] for r in variant_a]
        quality_b = [r['overall_quality_score'] for r in variant_b]
        t_stat, p_value = stats.ttest_ind(quality_a, quality_b)
        
        is_significant = p_value < 0.05
        winner = 'A' if avg_quality_a > avg_quality_b else 'B'
        lift_percent = ((max(avg_quality_a, avg_quality_b) / min(avg_quality_a, avg_quality_b)) - 1) * 100
        
        return {
            'experiment_id': experiment_id,
            'sample_size_a': len(variant_a),
            'sample_size_b': len(variant_b),
            'avg_quality_a': round(avg_quality_a, 2),
            'avg_quality_b': round(avg_quality_b, 2),
            'avg_rating_a': round(avg_rating_a, 2) if avg_rating_a else None,
            'avg_rating_b': round(avg_rating_b, 2) if avg_rating_b else None,
            'avg_cost_a': round(avg_cost_a, 4),
            'avg_cost_b': round(avg_cost_b, 4),
            't_statistic': round(t_stat, 4),
            'p_value': round(p_value, 4),
            'is_significant': is_significant,
            'winner': winner if is_significant else None,
            'lift_percent': round(lift_percent, 2),
            'confidence_level': '95%' if is_significant else '<95%',
            'recommendation': self._generate_recommendation(
                winner, is_significant, lift_percent, avg_cost_a, avg_cost_b
            )
        }
    
    def _generate_recommendation(
        self,
        winner: str,
        is_significant: bool,
        lift_percent: float,
        cost_a: float,
        cost_b: float
    ) -> str:
        """ç”Ÿæˆå®éªŒå»ºè®®"""
        if not is_significant:
            return "å®éªŒç»“æœæ— æ˜¾è‘—å·®å¼‚ï¼Œå»ºè®®ç»§ç»­æ”¶é›†æ•°æ®æˆ–å°è¯•æ›´å¤§çš„æ”¹åŠ¨"
        
        cost_diff_percent = abs(cost_a - cost_b) / min(cost_a, cost_b) * 100
        
        if lift_percent > 10 and cost_diff_percent < 20:
            return f"å˜ä½“{winner}æ˜æ˜¾ä¼˜äºå¦ä¸€å˜ä½“ï¼ˆæå‡{lift_percent:.1f}%ï¼‰ï¼Œä¸”æˆæœ¬ç›¸è¿‘ï¼Œå»ºè®®é‡‡ç”¨"
        elif lift_percent > 5 and cost_diff_percent < 10:
            return f"å˜ä½“{winner}è¡¨ç°æ›´å¥½ï¼ˆæå‡{lift_percent:.1f}%ï¼‰ï¼Œå»ºè®®é‡‡ç”¨"
        elif lift_percent < 3:
            return "è™½ç„¶æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œä½†æå‡å¹…åº¦è¾ƒå°ï¼Œå¯è€ƒè™‘å…¶ä»–ä¼˜åŒ–æ–¹å‘"
        else:
            return f"å˜ä½“{winner}æ›´ä¼˜ï¼ˆæå‡{lift_percent:.1f}%ï¼‰ï¼Œä½†éœ€æƒè¡¡æˆæœ¬å·®å¼‚"
```

---

## ğŸ“ˆ æ€§èƒ½åˆ†æä»ªè¡¨æ¿

### å…³é”®æŒ‡æ ‡å¯è§†åŒ–

#### 1. è´¨é‡è¶‹åŠ¿å›¾

```python
# APIç«¯ç‚¹ï¼šGET /api/analytics/quality-trend
{
    "params": {
        "time_range": "last_30_days",
        "group_by": "llm_backend"  # æˆ– "industry", "analysis_type"
    },
    "response": {
        "data": [
            {
                "date": "2026-01-06",
                "gemini": 85.3,
                "deepseek": 82.1,
                "openai": 87.6
            },
            ...
        ]
    }
}
```

**å¯è§†åŒ–**ï¼šæŠ˜çº¿å›¾
- Xè½´ï¼šæ—¥æœŸ
- Yè½´ï¼šå¹³å‡è´¨é‡åˆ† (0-100)
- å¤šæ¡çº¿ï¼šä¸åŒLLMåç«¯

#### 2. æˆæœ¬æ•ˆç‡çŸ©é˜µ

```python
# APIç«¯ç‚¹ï¼šGET /api/analytics/cost-efficiency
{
    "response": {
        "models": [
            {
                "name": "Gemini 2.5 Flash",
                "avg_quality": 85.3,
                "avg_cost": 0.023,
                "usage_count": 523
            },
            {
                "name": "DeepSeek Chat",
                "avg_quality": 82.1,
                "avg_cost": 0.008,
                "usage_count": 234
            },
            ...
        ]
    }
}
```

**å¯è§†åŒ–**ï¼šæ•£ç‚¹å›¾/æ°”æ³¡å›¾
- Xè½´ï¼šæˆæœ¬ ($/åˆ†æ)
- Yè½´ï¼šè´¨é‡åˆ†
- æ°”æ³¡å¤§å°ï¼šä½¿ç”¨æ¬¡æ•°
- ç†æƒ³ä½ç½®ï¼šå³ä¸Šè§’ï¼ˆé«˜è´¨é‡ã€ä½æˆæœ¬ï¼‰

#### 3. ç”¨æˆ·æ»¡æ„åº¦çƒ­åŠ›å›¾

```python
# APIç«¯ç‚¹ï¼šGET /api/analytics/satisfaction-heatmap
{
    "response": {
        "data": [
            ["tech", "comprehensive", 4.6],
            ["tech", "trend", 4.2],
            ["finance", "comprehensive", 4.8],
            ...
        ],
        "industries": ["tech", "finance", "developer", ...],
        "analysis_types": ["comprehensive", "trend", "signal", ...]
    }
}
```

**å¯è§†åŒ–**ï¼šçƒ­åŠ›å›¾
- Xè½´ï¼šè¡Œä¸š
- Yè½´ï¼šåˆ†æç±»å‹
- é¢œè‰²ï¼šå¹³å‡ç”¨æˆ·è¯„åˆ† (1-5æ˜Ÿ)

#### 4. Promptç‰ˆæœ¬å¯¹æ¯”è¡¨

```markdown
| ç‰ˆæœ¬  | è¡Œä¸š     | ä½¿ç”¨æ¬¡æ•° | å¹³å‡è´¨é‡åˆ† | å¹³å‡è¯„åˆ† | å¹³å‡æˆæœ¬ | èƒœç‡  | çŠ¶æ€   |
|-------|---------|---------|-----------|---------|---------|-------|--------|
| v1.3  | tech    | 523     | 87.3      | 4.6     | $0.023  | 68%   | æ´»è·ƒ   |
| v1.2  | tech    | 892     | 82.1      | 4.2     | $0.019  | 52%   | åºŸå¼ƒ   |
| v2.1  | finance | 234     | 91.2      | 4.8     | $0.031  | 75%   | æ´»è·ƒ   |
| v2.0  | finance | 567     | 88.5      | 4.5     | $0.028  | 63%   | åºŸå¼ƒ   |
```

**èƒœç‡**ï¼šåœ¨A/Bæµ‹è¯•ä¸­è·èƒœçš„æ¯”ä¾‹

---

## ğŸ› ï¸ å®ç°è®¡åˆ’

### Phase 1: åŸºç¡€è®¾æ–½ (é¢„è®¡1-2å‘¨)

**ç›®æ ‡**ï¼šå»ºç«‹è´¨é‡è¯„åˆ†çš„åŸºç¡€èƒ½åŠ›

- [ ] åˆ›å»ºæ•°æ®åº“è¡¨
  - [ ] `quality_metrics` è¡¨
  - [ ] `prompt_versions` è¡¨
  - [ ] `experiments` è¡¨
  - [ ] æ·»åŠ ç´¢å¼•

- [ ] å®ç°è´¨é‡è¯„åˆ†ç®—æ³•
  - [ ] å®Œæ•´æ€§è¯„åˆ†
  - [ ] ç»“æ„æ€§è¯„åˆ†
  - [ ] æ´å¯Ÿå¯†åº¦è®¡ç®—
  - [ ] å¯è¯»æ€§è¯„åˆ†
  - [ ] å…³é”®è¯è¦†ç›–
  - [ ] ç»¼åˆè´¨é‡åˆ†è®¡ç®—

- [ ] é›†æˆåˆ°åˆ†ææµç¨‹
  - [ ] åœ¨ `analyzer.py` ä¸­è°ƒç”¨è´¨é‡è¯„åˆ†
  - [ ] ä¿å­˜è´¨é‡æŒ‡æ ‡åˆ°æ•°æ®åº“
  - [ ] åœ¨åˆ†æè¯¦æƒ…é¡µå±•ç¤ºè´¨é‡åˆ†

- [ ] æ·»åŠ APIç«¯ç‚¹
  - [ ] `GET /api/analytics/quality-metrics/{analysis_id}`
  - [ ] `GET /api/analytics/quality-summary`

### Phase 2: ç”¨æˆ·åé¦ˆ (é¢„è®¡1å‘¨)

**ç›®æ ‡**ï¼šæ”¶é›†ç”¨æˆ·å¯¹åˆ†æè´¨é‡çš„åé¦ˆ

- [ ] å‰ç«¯UI
  - [ ] åˆ†æè¯¦æƒ…é¡µæ·»åŠ æ˜Ÿçº§è¯„åˆ†ç»„ä»¶
  - [ ] æ·»åŠ åé¦ˆæ–‡æœ¬æ¡†ï¼ˆå¯é€‰ï¼‰
  - [ ] "æœ‰å¸®åŠ©/æ— å¸®åŠ©"æŒ‰é’®

- [ ] åç«¯API
  - [ ] `POST /api/analyses/{id}/feedback` - æäº¤åé¦ˆ
  - [ ] `GET /api/analyses/{id}/feedback` - è·å–åé¦ˆ

- [ ] æ•°æ®å…³è”
  - [ ] å°†ç”¨æˆ·åé¦ˆæ›´æ–°åˆ° `quality_metrics` è¡¨
  - [ ] è®¡ç®—å¹³å‡ç”¨æˆ·è¯„åˆ†

### Phase 3: Promptç‰ˆæœ¬ç®¡ç† (é¢„è®¡3-5å¤©)

**ç›®æ ‡**ï¼šç®¡ç†å’Œè¿½è¸ªPromptçš„ä¸åŒç‰ˆæœ¬

- [ ] Promptç‰ˆæœ¬CRUD
  - [ ] `POST /api/prompts/versions` - åˆ›å»ºæ–°ç‰ˆæœ¬
  - [ ] `GET /api/prompts/versions` - åˆ—å‡ºæ‰€æœ‰ç‰ˆæœ¬
  - [ ] `PUT /api/prompts/versions/{id}/activate` - æ¿€æ´»ç‰ˆæœ¬
  - [ ] `GET /api/prompts/versions/{id}/stats` - ç‰ˆæœ¬ç»Ÿè®¡

- [ ] ç‰ˆæœ¬æ§åˆ¶é€»è¾‘
  - [ ] ä»ç°æœ‰Promptæ–‡ä»¶å¯¼å…¥åˆå§‹ç‰ˆæœ¬
  - [ ] æ”¯æŒåŸºäºçˆ¶ç‰ˆæœ¬åˆ›å»ºæ–°ç‰ˆæœ¬
  - [ ] è®°å½•å˜æ›´è¯´æ˜

### Phase 4: A/Bæµ‹è¯•æ¡†æ¶ (é¢„è®¡1-2å‘¨)

**ç›®æ ‡**ï¼šæ”¯æŒPromptçš„A/Bæµ‹è¯•

- [ ] å®éªŒç®¡ç†API
  - [ ] `POST /api/experiments` - åˆ›å»ºå®éªŒ
  - [ ] `GET /api/experiments` - åˆ—å‡ºå®éªŒ
  - [ ] `PUT /api/experiments/{id}/start` - å¯åŠ¨å®éªŒ
  - [ ] `PUT /api/experiments/{id}/stop` - åœæ­¢å®éªŒ
  - [ ] `GET /api/experiments/{id}/results` - æŸ¥çœ‹ç»“æœ

- [ ] æ ¸å¿ƒé€»è¾‘
  - [ ] å®ç° `ABTestManager` ç±»
  - [ ] å˜ä½“åˆ†é…ç®—æ³•ï¼ˆä¸€è‡´æ€§å“ˆå¸Œï¼‰
  - [ ] å®éªŒç»“æœè®°å½•
  - [ ] ç»Ÿè®¡åˆ†æï¼ˆt-testï¼‰

- [ ] é›†æˆåˆ°åˆ†ææµç¨‹
  - [ ] åœ¨ç”Ÿæˆåˆ†æå‰æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œä¸­çš„å®éªŒ
  - [ ] æ ¹æ®å®éªŒé…ç½®é€‰æ‹©Prompt
  - [ ] è®°å½•å®éªŒæ•°æ®

### Phase 5: åˆ†æä»ªè¡¨æ¿ (é¢„è®¡1-2å‘¨)

**ç›®æ ‡**ï¼šå¯è§†åŒ–å±•ç¤ºè´¨é‡æ•°æ®å’Œå®éªŒç»“æœ

- [ ] åç«¯API
  - [ ] `GET /api/analytics/quality-trend`
  - [ ] `GET /api/analytics/cost-efficiency`
  - [ ] `GET /api/analytics/satisfaction-heatmap`
  - [ ] `GET /api/analytics/prompt-comparison`

- [ ] å‰ç«¯é¡µé¢
  - [ ] åˆ›å»º `Analytics.tsx` é¡µé¢
  - [ ] è´¨é‡è¶‹åŠ¿å›¾ï¼ˆä½¿ç”¨ Chart.js æˆ– Rechartsï¼‰
  - [ ] æˆæœ¬æ•ˆç‡æ•£ç‚¹å›¾
  - [ ] ç”¨æˆ·æ»¡æ„åº¦çƒ­åŠ›å›¾
  - [ ] Promptç‰ˆæœ¬å¯¹æ¯”è¡¨

- [ ] äº¤äº’åŠŸèƒ½
  - [ ] æ—¶é—´èŒƒå›´ç­›é€‰
  - [ ] æŒ‰LLM/è¡Œä¸š/ç±»å‹ç­›é€‰
  - [ ] æ•°æ®å¯¼å‡ºï¼ˆCSV/Excelï¼‰

### Phase 6: è‡ªåŠ¨åŒ–ä¼˜åŒ– (å¯é€‰ï¼Œé¢„è®¡1å‘¨)

**ç›®æ ‡**ï¼šåŸºäºè´¨é‡æ•°æ®è‡ªåŠ¨è§¦å‘ä¼˜åŒ–

- [ ] å‘Šè­¦æœºåˆ¶
  - [ ] è´¨é‡åˆ†ä½äºé˜ˆå€¼æ—¶å‘é€é€šçŸ¥
  - [ ] ç”¨æˆ·è¯„åˆ†æŒç»­ä¸‹é™æ—¶å‘Šè­¦

- [ ] è‡ªåŠ¨å®éªŒè§¦å‘
  - [ ] æ£€æµ‹åˆ°è´¨é‡ä¸‹é™æ—¶è‡ªåŠ¨å¯åŠ¨A/Bæµ‹è¯•
  - [ ] æµ‹è¯•æ–°çš„Promptå˜ä½“

- [ ] æ¨èç³»ç»Ÿ
  - [ ] ä¸ºæ¯ä¸ªè¡Œä¸šæ¨èæœ€ä½³Prompt
  - [ ] ä¸ºæ¯ä¸ªç”¨æˆ·æ¨èæœ€ä½³LLMåç«¯

---

## ğŸ’¡ ä½¿ç”¨åœºæ™¯ç¤ºä¾‹

### åœºæ™¯1ï¼šè‡ªåŠ¨ç›‘æ§Promptæ€§èƒ½

```python
# åœ¨analyzer.pyä¸­é›†æˆè´¨é‡è¯„åˆ†
async def analyze(self, articles, analysis_type, ...):
    # ç”Ÿæˆåˆ†æ
    analysis = await self._generate_analysis(...)
    
    # è®¡ç®—è´¨é‡åˆ†
    quality_evaluator = QualityEvaluator()
    quality_metrics = quality_evaluator.evaluate(
        markdown_report=analysis.markdown_report,
        analysis_type=analysis_type,
        articles=articles,
        llm_backend=self.llm_backend,
        llm_model=self.model,
        processing_time=analysis.processing_time_seconds,
        token_usage=analysis.token_usage,
        estimated_cost=analysis.estimated_cost
    )
    
    # ä¿å­˜è´¨é‡æŒ‡æ ‡
    await self.db.save_quality_metrics(analysis.id, quality_metrics)
    
    # å¦‚æœè´¨é‡åˆ†ä½äºé˜ˆå€¼ï¼Œè§¦å‘å‘Šè­¦
    if quality_metrics['overall_quality_score'] < 70:
        await self._send_low_quality_alert(analysis.id, quality_metrics)
    
    return analysis
```

### åœºæ™¯2ï¼šä¼˜åŒ–ç‰¹å®šè¡Œä¸šçš„Prompt

```python
# ç®¡ç†å‘˜åˆ›å»ºA/Bæµ‹è¯•
experiment = await ab_test_manager.create_experiment(
    name="Developerè¡Œä¸šPrompt v2.0æµ‹è¯•",
    description="æµ‹è¯•å¢å¼ºä»£ç ç¤ºä¾‹å’ŒæŠ€æœ¯æ·±åº¦çš„æ–°ç‰ˆPrompt",
    industry="developer",
    analysis_type="comprehensive",
    variant_a_prompt_id="developer_v1_comprehensive",  # å½“å‰ç‰ˆæœ¬
    variant_b_prompt_id="developer_v2_comprehensive",  # æ–°ç‰ˆæœ¬
    traffic_split=0.5,  # 50/50æµé‡åˆ†é…
    min_samples_per_variant=30  # æ¯ä¸ªå˜ä½“è‡³å°‘30ä¸ªæ ·æœ¬
)

# å¯åŠ¨å®éªŒ
await ab_test_manager.start_experiment(experiment.id)

# 2å‘¨åï¼Œæ£€æŸ¥ç»“æœ
results = await ab_test_manager.analyze_experiment(experiment.id)

# è¾“å‡ºç¤ºä¾‹ï¼š
# {
#     "sample_size_a": 45,
#     "sample_size_b": 47,
#     "avg_quality_a": 82.3,
#     "avg_quality_b": 89.7,
#     "p_value": 0.003,
#     "is_significant": True,
#     "winner": "B",
#     "lift_percent": 9.0,
#     "recommendation": "å˜ä½“Bæ˜æ˜¾ä¼˜äºå¦ä¸€å˜ä½“ï¼ˆæå‡9.0%ï¼‰ï¼Œå»ºè®®é‡‡ç”¨"
# }

# åº”ç”¨è·èƒœç‰ˆæœ¬
if results['is_significant'] and results['winner'] == 'B':
    await prompt_manager.activate_version("developer_v2_comprehensive")
    await ab_test_manager.stop_experiment(experiment.id, reason="Winner applied")
```

### åœºæ™¯3ï¼šç”¨æˆ·åé¦ˆé©±åŠ¨æ”¹è¿›

```python
# 1. æ”¶é›†ç”¨æˆ·åé¦ˆ
# ç”¨æˆ·åœ¨å‰ç«¯ç»™åˆ†ææ‰“2æ˜Ÿï¼Œè¯„è®ºï¼š"å»ºè®®å¤ªç¬¼ç»Ÿï¼Œæ²¡æœ‰å…·ä½“æ¡ˆä¾‹"

# 2. ç³»ç»Ÿåˆ†æä½åˆ†åé¦ˆ
low_rated = await db.get_analyses_with_rating(max_rating=3, limit=100)

# 3. æå–å…±æ€§é—®é¢˜
feedback_analysis = analyze_feedback_patterns(low_rated)
# ç»“æœï¼š
# {
#     "common_complaints": [
#         {"keyword": "å»ºè®®", "count": 45, "sentiment": "negative"},
#         {"keyword": "æ¡ˆä¾‹", "count": 38, "sentiment": "negative"},
#         {"keyword": "å…·ä½“", "count": 32, "sentiment": "negative"}
#     ],
#     "affected_industries": ["tech", "developer"],
#     "affected_analysis_types": ["comprehensive"]
# }

# 4. è°ƒæ•´Prompt
new_prompt = enhance_prompt(
    base_prompt="prompts/tech_comprehensive_v1.yaml",
    improvements=[
        "åœ¨æ‰§è¡Œå»ºè®®éƒ¨åˆ†å¢åŠ å…·ä½“æ¡ˆä¾‹",
        "æ¯æ¡å»ºè®®æä¾›å¯æ“ä½œçš„æ­¥éª¤",
        "å¼•ç”¨æºæ–‡ç« ä¸­çš„æ•°æ®æ”¯æ’‘å»ºè®®"
    ]
)

# 5. åˆ›å»ºA/Bæµ‹è¯•éªŒè¯æ”¹è¿›
experiment = await ab_test_manager.create_experiment(
    name="Techç»¼åˆåˆ†æï¼šå¢å¼ºå»ºè®®å…·ä½“æ€§",
    industry="tech",
    analysis_type="comprehensive",
    variant_a_prompt_id="tech_v1",
    variant_b_prompt_id=new_prompt.id
)

# 6. ç­‰å¾…ç»“æœå¹¶åº”ç”¨
```

### åœºæ™¯4ï¼šå¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”

```python
# å®šæœŸç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
report = await analytics.generate_model_comparison_report(
    time_range="last_30_days"
)

# è¾“å‡ºç¤ºä¾‹ï¼š
# {
#     "models": [
#         {
#             "name": "Gemini 2.5 Flash",
#             "avg_quality": 85.3,
#             "avg_cost": 0.023,
#             "avg_time": 12.5,
#             "usage_count": 523,
#             "user_rating": 4.6,
#             "strengths": ["å¿«é€Ÿ", "æˆæœ¬é€‚ä¸­"],
#             "weaknesses": ["æ·±åº¦åˆ†æç•¥å¼±"]
#         },
#         {
#             "name": "DeepSeek Chat",
#             "avg_quality": 82.1,
#             "avg_cost": 0.008,
#             "avg_time": 18.3,
#             "usage_count": 234,
#             "user_rating": 4.2,
#             "strengths": ["æˆæœ¬æä½"],
#             "weaknesses": ["é€Ÿåº¦è¾ƒæ…¢", "è´¨é‡ç•¥ä½"]
#         },
#         {
#             "name": "GPT-4o",
#             "avg_quality": 91.2,
#             "avg_cost": 0.087,
#             "avg_time": 15.2,
#             "usage_count": 89,
#             "user_rating": 4.9,
#             "strengths": ["è´¨é‡æœ€é«˜", "æ·±åº¦åˆ†æå¼º"],
#             "weaknesses": ["æˆæœ¬é«˜"]
#         }
#     ],
#     "recommendation": "æ—¥å¸¸åˆ†æä½¿ç”¨Gemini 2.5ï¼Œé‡è¦åˆ†æä½¿ç”¨GPT-4o"
# }
```

---

## ğŸ“Š é¢„æœŸæ”¶ç›Š

### 1. è´¨é‡æå‡

- **åŸºçº¿**ï¼šå½“å‰å¹³å‡è´¨é‡åˆ† ~75-80ï¼ˆä¼°è®¡ï¼‰
- **ç›®æ ‡**ï¼šé€šè¿‡æŒç»­ä¼˜åŒ–æå‡è‡³ 85-90
- **æå‡å¹…åº¦**ï¼š15-25%
- **å®ç°è·¯å¾„**ï¼š
  - ç¬¬1ä¸ªæœˆï¼šè¯†åˆ«ä½åˆ†æ¨¡å¼ï¼Œä¿®å¤æ˜æ˜¾é—®é¢˜ â†’ +5åˆ†
  - ç¬¬2-3ä¸ªæœˆï¼šA/Bæµ‹è¯•ä¼˜åŒ–Prompt â†’ +5åˆ†
  - ç¬¬4-6ä¸ªæœˆï¼šåŸºäºç”¨æˆ·åé¦ˆç²¾ç»†è°ƒä¼˜ â†’ +5åˆ†

### 2. æˆæœ¬ä¼˜åŒ–

- **ç°çŠ¶**ï¼šæ¯æ¬¡åˆ†æå¹³å‡æˆæœ¬ $0.02-0.03
- **ä¼˜åŒ–æ–¹å‘**ï¼š
  - è¯†åˆ«"æ€§ä»·æ¯”æœ€ä¼˜"æ¨¡å‹é…ç½®
  - åœ¨ä¿è¯è´¨é‡çš„å‰æä¸‹é€‰æ‹©æ›´ä¾¿å®œçš„æ¨¡å‹
  - é¿å…è¿‡åº¦ä½¿ç”¨æ˜‚è´µæ¨¡å‹
- **é¢„æœŸèŠ‚çœ**ï¼š10-20%çš„æˆæœ¬ï¼ˆçº¦$0.002-0.006/æ¬¡ï¼‰
- **å¹´åº¦å½±å“**ï¼šå¦‚æœæ¯æœˆ1000æ¬¡åˆ†æï¼Œå¹´èŠ‚çœ $240-720

### 3. ç”¨æˆ·æ»¡æ„åº¦

- **åŸºçº¿**ï¼šå½“å‰ç”¨æˆ·è¯„åˆ†æœªçŸ¥ï¼ˆéœ€è¦å…ˆå®ç°åé¦ˆåŠŸèƒ½ï¼‰
- **ç›®æ ‡**ï¼šå¹³å‡4.5æ˜Ÿä»¥ä¸Šï¼ˆæ»¡åˆ†5æ˜Ÿï¼‰
- **æå‡ç­–ç•¥**ï¼š
  - å¿«é€Ÿå“åº”ä½åˆ†åé¦ˆ
  - é’ˆå¯¹æ€§ä¼˜åŒ–é—®é¢˜æœ€å¤šçš„è¡Œä¸š/ç±»å‹
  - æŒç»­è¿­ä»£Prompt

### 4. å¯è¿½æº¯æ€§å’Œå¯è§£é‡Šæ€§

- **å½“å‰é—®é¢˜**ï¼šåˆ†æè´¨é‡å¥½åæ— æ³•é‡åŒ–ï¼Œé—®é¢˜éš¾ä»¥å®šä½
- **æ”¹è¿›å**ï¼š
  - æ¯ä¸ªåˆ†æéƒ½æœ‰è´¨é‡åˆ†å’Œåˆ†é¡¹å¾—åˆ†
  - å¯è¿½æº¯åˆ°ä½¿ç”¨çš„Promptç‰ˆæœ¬å’ŒLLM
  - å¯å¯¹æ¯”ä¸åŒé…ç½®çš„æ•ˆæœ
  - ä¾¿äºå‘ç”¨æˆ·è§£é‡Šåˆ†æè´¨é‡

### 5. å¼€å‘æ•ˆç‡

- **å½“å‰**ï¼šPromptä¼˜åŒ–é ä¸»è§‚åˆ¤æ–­ï¼Œç¼ºä¹æ•°æ®æ”¯æ’‘
- **æ”¹è¿›å**ï¼š
  - A/Bæµ‹è¯•æä¾›å®¢è§‚æ•°æ®
  - å¿«é€ŸéªŒè¯Promptæ”¹åŠ¨æ•ˆæœ
  - é¿å…"æ”¹è¿›"å®é™…ä¸Šå˜å·®
  - ç§¯ç´¯æœ€ä½³å®è·µ

---

## ğŸ” éšç§å’Œä¼¦ç†è€ƒè™‘

### 1. ç”¨æˆ·éšç§

- è´¨é‡æŒ‡æ ‡ä¸åŒ…å«ç”¨æˆ·ä¸ªäººä¿¡æ¯
- ç”¨æˆ·åé¦ˆå¯é€‰åŒ¿å
- èšåˆç»Ÿè®¡æ•°æ®ï¼Œä¸æš´éœ²å•ä¸ªç”¨æˆ·è¡Œä¸º

### 2. åè§ç¼“è§£

- å®šæœŸæ£€æŸ¥ä¸åŒè¡Œä¸š/ç±»å‹çš„è´¨é‡åˆ†å¸ƒ
- é¿å…ç®—æ³•å¯¹æŸäº›è¡Œä¸šäº§ç”Ÿç³»ç»Ÿæ€§åè§
- å¤šæ ·åŒ–æµ‹è¯•æ•°æ®æº

### 3. é€æ˜åº¦

- å‘ç”¨æˆ·å±•ç¤ºè´¨é‡åˆ†è®¡ç®—æ–¹å¼
- è¯´æ˜A/Bæµ‹è¯•çš„ç›®çš„å’Œå½±å“
- å…è®¸ç”¨æˆ·é€‰æ‹©é€€å‡ºå®éªŒ

---

## ğŸ“š ç›¸å…³èµ„æº

### è®ºæ–‡å’Œæ–‡çŒ®

1. **LLM Output Quality Evaluation**
   - "Automatic Evaluation of Text Generation"
   - "Metrics for Natural Language Generation"

2. **A/B Testing Best Practices**
   - "Trustworthy Online Controlled Experiments" (Microsoft)
   - "Practical Guide to Controlled Experiments on the Web" (Google)

3. **Prompt Engineering**
   - "The Prompt Report: A Systematic Survey"
   - "Large Language Model Prompt Engineering"

### å·¥å…·å’Œåº“

1. **ç»Ÿè®¡åˆ†æ**
   - `scipy.stats` - Tæ£€éªŒã€å¡æ–¹æ£€éªŒ
   - `statsmodels` - æ›´å¤šç»Ÿè®¡æ¨¡å‹

2. **æ–‡æœ¬åˆ†æ**
   - `jieba` - ä¸­æ–‡åˆ†è¯
   - `nltk` - è‡ªç„¶è¯­è¨€å¤„ç†
   - `textstat` - å¯è¯»æ€§è¯„åˆ†

3. **å¯è§†åŒ–**
   - `matplotlib` / `seaborn` - åç«¯å›¾è¡¨ç”Ÿæˆ
   - `Chart.js` / `Recharts` - å‰ç«¯äº¤äº’å¼å›¾è¡¨

### ç¤ºä¾‹é¡¹ç›®

1. **ç±»ä¼¼ç³»ç»Ÿ**
   - Google Experiments Platform
   - Optimizely
   - LaunchDarkly

2. **å¼€æºå‚è€ƒ**
   - [Evidently AI](https://github.com/evidentlyai/evidently) - MLæ¨¡å‹ç›‘æ§
   - [PlanOut](https://github.com/facebook/planout) - Facebookçš„A/Bæµ‹è¯•æ¡†æ¶

---

## ğŸ¯ æ€»ç»“

åˆ†æè´¨é‡è·Ÿè¸ªç³»ç»Ÿæ˜¯ä¸€ä¸ª**æ•°æ®é©±åŠ¨çš„æŒç»­æ”¹è¿›æ¡†æ¶**ï¼Œé€šè¿‡ä»¥ä¸‹æ–¹å¼æå‡NewsGapçš„åˆ†æè´¨é‡ï¼š

1. **é‡åŒ–è¯„ä¼°**ï¼š5ä¸ªç»´åº¦çš„è‡ªåŠ¨è´¨é‡è¯„åˆ†
2. **ç”¨æˆ·åé¦ˆ**ï¼šæ”¶é›†çœŸå®ç”¨æˆ·çš„è¯„ä»·
3. **A/Bæµ‹è¯•**ï¼šç§‘å­¦éªŒè¯Promptæ”¹è¿›æ•ˆæœ
4. **æ€§èƒ½ç›‘æ§**ï¼šè¿½è¸ªè´¨é‡è¶‹åŠ¿å’Œæ¨¡å‹è¡¨ç°
5. **é—­ç¯ä¼˜åŒ–**ï¼šåé¦ˆé©±åŠ¨çš„Promptè¿­ä»£

**å®æ–½å»ºè®®**ï¼š
- ä¼˜å…ˆå®ç° Phase 1ï¼ˆè´¨é‡è¯„åˆ†ï¼‰å’Œ Phase 2ï¼ˆç”¨æˆ·åé¦ˆï¼‰
- ç§¯ç´¯2-4å‘¨æ•°æ®åå†å¯åŠ¨A/Bæµ‹è¯•
- é€æ­¥å®Œå–„ï¼Œé¿å…ä¸€æ¬¡æ€§æŠ•å…¥è¿‡å¤§

**å…³é”®æˆåŠŸå› ç´ **ï¼š
- å‡†ç¡®çš„è´¨é‡è¯„åˆ†ç®—æ³•
- è¶³å¤Ÿçš„æ ·æœ¬é‡ï¼ˆæ¯ä¸ªå®éªŒè‡³å°‘30ä¸ªæ ·æœ¬ï¼‰
- æŒç»­çš„è¿­ä»£å’Œä¼˜åŒ–æ„è¯†

---

**æœ€åæ›´æ–°**ï¼š2026-02-05  
**ä½œè€…**ï¼šKyusei  
**ç‰ˆæœ¬**ï¼šv1.0
